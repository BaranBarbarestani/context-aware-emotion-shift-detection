# demo_notebook.ipynb

# Cell 1: Imports and load model/tokenizer
from transformers import BertTokenizer
from model import EmotionShiftDetector
import torch

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = EmotionShiftDetector().to(device)
model.load_state_dict(torch.load('best_model.pt', map_location=device))
model.eval()

# Cell 2: Function to predict shifts in a conversation
def predict_shifts(conversation_texts):
    inputs = tokenizer(conversation_texts, padding=True, truncation=True, return_tensors='pt')
    input_ids = inputs['input_ids'].to(device)
    attention_mask = inputs['attention_mask'].to(device)
    audio_feats = torch.zeros((len(conversation_texts), 13)).to(device)  # dummy audio
    
    with torch.no_grad():
        logits = model(input_ids, attention_mask, audio_feats)
        preds = torch.argmax(logits, dim=1).cpu().numpy()
    return preds

# Cell 3: Test example conversation
conversation = [
    "I'm feeling great today!",
    "Oh, that's awesome to hear.",
    "Actually, I'm a bit worried about tomorrow.",
    "Why's that?",
    "I have a big presentation.",
]

shifts = predict_shifts(conversation)
for i, (utt, shift) in enumerate(zip(conversation, shifts)):
    print(f"Utterance {i}: '{utt}' --> Emotion Shift Detected: {'Yes' if shift == 1 else 'No'}")
